#!/usr/bin/env python3
"""
Ejemplo b√°sico de uso del pipeline unificado MDS.

Este ejemplo demuestra:
1. Configuraci√≥n simple de variables
2. Ejecuci√≥n del pipeline
3. Validaci√≥n b√°sica de resultados
"""

import yaml
import subprocess
from pathlib import Path
import sys
import logging

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def create_basic_config():
    """Crea una configuraci√≥n b√°sica para an√°lisis MDS."""
    
    config = {
        'data_sources': {
            'clinical_data': 'data/IPSSMol/df_clinical.tsv',
            'mutation_vaf_data': 'data/IPSSMol/maf.tsv',
            'gene_embeddings': 'data/scGPT/gene_embeddings.csv'
        },
        
        'variable_processing': {
            # Selecci√≥n de genes m√°s importantes en MDS
            'gene_selection': [
                'TP53', 'ASXL1', 'RUNX1', 'SRSF2', 'SF3B1',
                'TET2', 'DNMT3A', 'IDH2', 'CBL', 'EZH2'
            ],
            
            # Variables cl√≠nicas continuas
            'continuous_variables': [
                'AGE',          # Edad
                'HB',           # Hemoglobina
                'PLT',          # Plaquetas
                'ANC',          # Neutr√≥filos
                'BM_BLAST'      # Blastos en m√©dula √≥sea
            ],
            
            # Variables categ√≥ricas
            'categorical_variables': [
                'SEX'           # Sexo (M/F)
            ],
            
            # Variables binarias
            'binary_variables': [
                'AML_TRANSF'    # Transformaci√≥n a AML
            ],
            
            # Variables de supervivencia
            'survival_variables': {
                'time_variable': 'LFS_YEARS',    # Tiempo libre de leucemia
                'status_variable': 'LFS_STATUS'  # Estado (0=censurado, 1=evento)
            }
        },
        
        'cross_validation': {
            'fold_column': 'fold'  # Columna con informaci√≥n de folds
        },
        
        'data_generation': {
            'output_formats': ['table', 'graph'],  # Generar ambos formatos
            
            'table_format': {
                'output_filename': 'basic_table'
            },
            
            'graph_format': {
                'output_filename': 'basic_graph'
            }
        },
        
        'output': {
            'file_prefix': 'basic_example'  # Prefijo para archivos de salida
        }
    }
    
    return config

def run_basic_pipeline():
    """Ejecuta el pipeline con configuraci√≥n b√°sica."""
    
    logger.info("üöÄ Iniciando ejemplo b√°sico del pipeline MDS")
    
    # 1. Crear configuraci√≥n
    logger.info("üìã Creando configuraci√≥n b√°sica...")
    config = create_basic_config()
    
    # Guardar configuraci√≥n
    config_file = Path('configs/basic_example.yaml')
    config_file.parent.mkdir(exist_ok=True)
    
    with open(config_file, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
    
    logger.info(f"‚úì Configuraci√≥n guardada en: {config_file}")
    
    # 2. Verificar archivos de entrada
    logger.info("üìÇ Verificando archivos de entrada...")
    base_path = Path('../../')  # Ajustar seg√∫n la estructura
    
    required_files = [
        base_path / config['data_sources']['clinical_data'],
        base_path / config['data_sources']['mutation_vaf_data']
    ]
    
    missing_files = []
    for file_path in required_files:
        if not file_path.exists():
            missing_files.append(str(file_path))
        else:
            logger.info(f"‚úì Archivo encontrado: {file_path}")
    
    if missing_files:
        logger.error(f"‚ùå Archivos faltantes: {missing_files}")
        logger.info("üí° Aseg√∫rate de que los datos est√©n en la ubicaci√≥n correcta")
        return False
    
    # 3. Ejecutar pipeline
    logger.info("‚öôÔ∏è Ejecutando pipeline...")
    output_dir = 'results/basic_example'
    
    cmd = [
        sys.executable, 'prepare_data_unified.py',
        '--config', str(config_file),
        '--output', output_dir,
        '--verbose'
    ]
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
        
        if result.returncode == 0:
            logger.info("‚úÖ Pipeline ejecutado exitosamente")
            logger.info(f"üìÅ Resultados disponibles en: {output_dir}")
        else:
            logger.error("‚ùå Error ejecutando pipeline")
            logger.error(f"STDERR: {result.stderr}")
            return False
            
    except subprocess.TimeoutExpired:
        logger.error("‚ùå Pipeline timeout (>5 min)")
        return False
    except Exception as e:
        logger.error(f"‚ùå Error inesperado: {e}")
        return False
    
    # 4. Verificar resultados
    logger.info("üîç Verificando resultados...")
    output_path = Path(output_dir)
    
    expected_files = [
        output_path / 'basic_example_table.pkl',
        output_path / 'basic_example_graph.pt'
    ]
    
    for expected_file in expected_files:
        if expected_file.exists():
            size_mb = expected_file.stat().st_size / (1024 * 1024)
            logger.info(f"‚úì Generado: {expected_file.name} ({size_mb:.2f} MB)")
        else:
            logger.warning(f"‚ö† No encontrado: {expected_file.name}")
    
    # 5. Mostrar resumen
    logger.info("\n" + "="*60)
    logger.info("üìä RESUMEN DEL EJEMPLO B√ÅSICO")
    logger.info("="*60)
    logger.info(f"Genes seleccionados: {len(config['variable_processing']['gene_selection'])}")
    logger.info(f"Variables cl√≠nicas: {len(config['variable_processing']['continuous_variables']) + len(config['variable_processing']['categorical_variables']) + len(config['variable_processing']['binary_variables'])}")
    logger.info(f"Formatos generados: {', '.join(config['data_generation']['output_formats'])}")
    logger.info(f"Directorio de salida: {output_dir}")
    logger.info("="*60)
    
    return True

def validate_results():
    """Ejecuta validaci√≥n b√°sica de los resultados."""
    
    logger.info("üî¨ Ejecutando validaci√≥n b√°sica...")
    
    output_dir = 'results/basic_example'
    
    # Validaci√≥n de calidad
    cmd_quality = [
        sys.executable, 'tests/validate_step3c.py',
        '--data-dir', output_dir
    ]
    
    try:
        result = subprocess.run(cmd_quality, capture_output=True, text=True, timeout=60)
        
        if result.returncode == 0:
            logger.info("‚úÖ Validaci√≥n de calidad exitosa")
        else:
            logger.warning("‚ö† Problemas en validaci√≥n de calidad")
            logger.warning(f"Detalles: {result.stderr}")
    
    except Exception as e:
        logger.warning(f"‚ö† Error en validaci√≥n: {e}")

def main():
    """Funci√≥n principal del ejemplo b√°sico."""
    
    # Cambiar al directorio correcto
    script_dir = Path(__file__).parent.parent
    original_dir = Path.cwd()
    
    try:
        import os
        os.chdir(script_dir)
        
        logger.info(f"üìÅ Directorio de trabajo: {Path.cwd()}")
        
        # Ejecutar pipeline
        success = run_basic_pipeline()
        
        if success:
            # Validar resultados
            validate_results()
            
            logger.info("\nüéâ ¬°Ejemplo b√°sico completado exitosamente!")
            logger.info("üí° Revisa los archivos generados en results/basic_example/")
            logger.info("üìñ Para m√°s ejemplos, consulta el directorio examples/")
            
            return 0
        else:
            logger.error("\nüí• El ejemplo b√°sico fall√≥")
            logger.info("üîß Revisa los logs anteriores para diagnosticar el problema")
            return 1
    
    finally:
        os.chdir(original_dir)

if __name__ == "__main__":
    exit(main())
