#!/usr/bin/env python3
"""
Script automatizado para ejecutar el pipeline completo y validar la calidad de datos.
Combina la ejecuci√≥n del pipeline (Paso 3A) con la validaci√≥n de calidad (Paso 3C).
"""
import sys
import os
from pathlib import Path
import logging
import subprocess
import argparse
import yaml
import json

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def run_pipeline_and_validate(config_file: str, output_dir: str, verbose: bool = False) -> bool:
    """
    Ejecuta el pipeline y valida la calidad de datos.
    
    Args:
        config_file: Archivo de configuraci√≥n del pipeline
        output_dir: Directorio de salida
        verbose: Activar logging detallado
        
    Returns:
        True si todo fue exitoso
    """
    logger.info("üöÄ Iniciando ejecuci√≥n automatizada del pipeline y validaci√≥n...")
    
    try:
        # Preparar directorios
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        script_dir = Path(__file__).parent.parent
        pipeline_script = script_dir / "prepare_data_unified.py"
        validator_script = Path(__file__).parent / "validate_step3c.py"
        
        # Paso 1: Ejecutar pipeline
        logger.info("üìä Paso 1: Ejecutando pipeline de preparaci√≥n de datos...")
        
        pipeline_cmd = [
            sys.executable,
            str(pipeline_script),
            "--config", config_file,
            "--output", output_dir
        ]
        
        if verbose:
            pipeline_cmd.append("--verbose")
        
        logger.info(f"Comando pipeline: {' '.join(pipeline_cmd)}")
        
        result = subprocess.run(
            pipeline_cmd,
            capture_output=True,
            text=True,
            timeout=300  # 5 minutos timeout
        )
        
        if result.returncode != 0:
            logger.error("‚ùå Pipeline fall√≥")
            logger.error(f"STDOUT: {result.stdout}")
            logger.error(f"STDERR: {result.stderr}")
            return False
        
        logger.info("‚úÖ Pipeline completado exitosamente")
        
        # Paso 2: Validar calidad de datos
        logger.info("üîç Paso 2: Validando calidad de datos generados...")
        
        validator_cmd = [
            sys.executable,
            str(validator_script),
            "--data-dir", output_dir
        ]
        
        if verbose:
            validator_cmd.append("--verbose")
        
        logger.info(f"Comando validador: {' '.join(validator_cmd)}")
        
        result = subprocess.run(
            validator_cmd,
            capture_output=True,
            text=True,
            timeout=120  # 2 minutos timeout
        )
        
        # Mostrar output del validador
        if result.stdout:
            print("\n" + "="*60)
            print("REPORTE DE VALIDACI√ìN DE CALIDAD")
            print("="*60)
            print(result.stdout)
        
        if result.returncode != 0:
            logger.error("‚ùå Validaci√≥n de calidad fall√≥")
            if result.stderr:
                logger.error(f"STDERR: {result.stderr}")
            return False
        
        logger.info("‚úÖ Validaci√≥n de calidad completada exitosamente")
        
        # Paso 3: Resumen final
        logger.info("üìã Paso 3: Generando resumen final...")
        
        summary = generate_execution_summary(config_file, output_dir)
        
        summary_file = output_path / "execution_summary.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"üìÑ Resumen guardado en: {summary_file}")
        
        logger.info("üéâ Ejecuci√≥n automatizada completada exitosamente!")
        return True
        
    except subprocess.TimeoutExpired:
        logger.error("‚ùå Timeout en la ejecuci√≥n")
        return False
    except Exception as e:
        logger.error(f"‚ùå Error en ejecuci√≥n automatizada: {e}")
        import traceback
        logger.error(f"Traceback: {traceback.format_exc()}")
        return False


def generate_execution_summary(config_file: str, output_dir: str) -> dict:
    """Genera resumen de la ejecuci√≥n."""
    summary = {
        'execution_timestamp': str(pd.Timestamp.now()),
        'config_file': config_file,
        'output_directory': output_dir,
        'pipeline_status': 'completed',
        'validation_status': 'completed',
        'generated_files': [],
        'file_sizes': {}
    }
    
    try:
        output_path = Path(output_dir)
        
        # Listar archivos generados
        for file_path in output_path.iterdir():
            if file_path.is_file():
                summary['generated_files'].append(file_path.name)
                summary['file_sizes'][file_path.name] = file_path.stat().st_size
        
        # Cargar configuraci√≥n usada
        with open(config_file, 'r', encoding='utf-8') as f:
            if config_file.endswith('.yaml') or config_file.endswith('.yml'):
                config_data = yaml.safe_load(f)
            else:
                config_data = json.load(f)
        
        summary['config_summary'] = {
            'output_formats': config_data.get('data_generation', {}).get('output_formats', []),
            'gene_selection': len(config_data.get('variable_processing', {}).get('gene_selection', [])),
            'clinical_variables': len(config_data.get('variable_processing', {}).get('continuous_variables', [])) + 
                                len(config_data.get('variable_processing', {}).get('categorical_variables', [])) +
                                len(config_data.get('variable_processing', {}).get('binary_variables', []))
        }
        
    except Exception as e:
        logger.warning(f"‚ö† Error generando resumen: {e}")
        summary['error'] = str(e)
    
    return summary


def main():
    """Funci√≥n principal."""
    parser = argparse.ArgumentParser(
        description="Ejecutor Automatizado del Pipeline + Validaci√≥n de Calidad",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ejemplos de uso:
  python run_pipeline_and_validate.py --config configs/real_data_config.yaml --output results/test_run
  python run_pipeline_and_validate.py --config configs/real_data_config.yaml --output results/production --verbose
        """
    )
    
    parser.add_argument(
        '--config', '-c',
        type=str,
        required=True,
        help='Archivo de configuraci√≥n para el pipeline'
    )
    
    parser.add_argument(
        '--output', '-o',
        type=str,
        required=True,
        help='Directorio de salida para los datos generados'
    )
    
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='Activar logging detallado'
    )
    
    args = parser.parse_args()
    
    # Configurar nivel de logging
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    try:
        success = run_pipeline_and_validate(
            config_file=args.config,
            output_dir=args.output,
            verbose=args.verbose
        )
        
        if success:
            logger.info("üéâ Proceso completo exitoso!")
            return 0
        else:
            logger.error("üí• El proceso fall√≥")
            return 1
            
    except Exception as e:
        logger.error(f"Error en proceso principal: {e}")
        return 1


if __name__ == "__main__":
    import pandas as pd  # Importar aqu√≠ para evitar error si no est√° disponible
    exit(main())
