# Pipeline Unificado de PreparaciÃ³n de Datos MDS

Este directorio contiene el pipeline unificado para la preparaciÃ³n de datos de sÃ­ndrome mielodisplÃ¡sico (MDS) que permite generar datos compatibles con modelos de supervivencia tanto de redes neuronales (NN) como de redes de grafos neuronales (GNN).

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n General](#descripciÃ³n-general)
- [CaracterÃ­sticas](#caracterÃ­sticas)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [InstalaciÃ³n y ConfiguraciÃ³n](#instalaciÃ³n-y-configuraciÃ³n)
- [GuÃ­a de Uso](#guÃ­a-de-uso)
- [Ejemplos PrÃ¡cticos](#ejemplos-prÃ¡cticos)
- [ValidaciÃ³n y Pruebas](#validaciÃ³n-y-pruebas)
- [Troubleshooting](#troubleshooting)

## ğŸ¯ DescripciÃ³n General

El pipeline unificado permite:

1. **PreparaciÃ³n flexible de datos**: SelecciÃ³n configurable de variables clÃ­nicas y genÃ©ticas
2. **MÃºltiples formatos de salida**: GeneraciÃ³n de datos para modelos de tabla (NN) y grafo (GNN)
3. **Cross-validation integrada**: Uso de folds pre-generados para validaciÃ³n cruzada
4. **ValidaciÃ³n automatizada**: VerificaciÃ³n de calidad de datos y compatibilidad con modelos
5. **ConfiguraciÃ³n YAML**: Control total mediante archivos de configuraciÃ³n

## âœ¨ CaracterÃ­sticas

- âœ… **Modular y extensible**: Arquitectura basada en componentes reutilizables
- âœ… **Docker compatible**: EjecuciÃ³n en contenedores para reproducibilidad
- âœ… **Logging detallado**: Seguimiento completo del procesamiento
- âœ… **ValidaciÃ³n exhaustiva**: VerificaciÃ³n automÃ¡tica de calidad y compatibilidad
- âœ… **Flexible**: Soporte para diferentes tipos de variables y embeddings

## ğŸ“ Estructura del Proyecto

```
scripts/3.GeneticScores/
â”œâ”€â”€ prepare_data_unified.py          # Script principal del pipeline
â”œâ”€â”€ utils/                           # MÃ³dulos utilitarios
â”‚   â”œâ”€â”€ data_loader.py              # Carga de datos (clÃ­nicos, mutaciones, embeddings)
â”‚   â”œâ”€â”€ clinical_processor.py       # Procesamiento de variables clÃ­nicas
â”‚   â””â”€â”€ data_generators.py          # GeneraciÃ³n de formatos tabla/grafo
â”œâ”€â”€ configs/                         # Archivos de configuraciÃ³n
â”‚   â”œâ”€â”€ real_data_config.yaml       # ConfiguraciÃ³n para datos reales
â”‚   â”œâ”€â”€ test_config.yaml           # ConfiguraciÃ³n para pruebas
â”‚   â””â”€â”€ minimal_config.yaml        # ConfiguraciÃ³n mÃ­nima
â”œâ”€â”€ tests/                          # Scripts de validaciÃ³n
â”‚   â”œâ”€â”€ validate_step2b.py          # ValidaciÃ³n de integraciÃ³n
â”‚   â”œâ”€â”€ validate_step3c.py          # ValidaciÃ³n de calidad de datos
â”‚   â”œâ”€â”€ validate_step3d.py          # ValidaciÃ³n de compatibilidad con modelos
â”‚   â””â”€â”€ run_pipeline_and_validate.py # EjecuciÃ³n automatizada
â”œâ”€â”€ examples/                       # Ejemplos de uso
â”‚   â”œâ”€â”€ basic_usage.py              # Ejemplo bÃ¡sico
â”‚   â”œâ”€â”€ advanced_usage.py           # Ejemplo avanzado
â”‚   â””â”€â”€ custom_config_example.py    # ConfiguraciÃ³n personalizada
â””â”€â”€ docs/                          # DocumentaciÃ³n adicional
    â”œâ”€â”€ configuration_guide.md      # GuÃ­a de configuraciÃ³n
    â”œâ”€â”€ validation_guide.md         # GuÃ­a de validaciÃ³n
    â””â”€â”€ docker_usage.md            # Uso con Docker
```

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Requisitos del Sistema

- Python 3.8+
- Docker (recomendado para reproducibilidad)
- Dependencias de Python (ver `requirements.txt`)

### InstalaciÃ³n Local

```bash
# Clonar repositorio (si no lo tienes)
git clone <repo-url>
cd MDS_subtypes/scripts/3.GeneticScores

# Instalar dependencias
pip install -r requirements.txt

# Verificar instalaciÃ³n
python prepare_data_unified.py --help
```

### Uso con Docker (Recomendado)

```bash
# Construir imagen (si no existe)
docker build -t mds_subtypes_python:1.6 .

# Verificar imagen
docker run --rm mds_subtypes_python:1.6 python --version
```

## ğŸ“– GuÃ­a de Uso

### 1. ConfiguraciÃ³n BÃ¡sica

Crea un archivo de configuraciÃ³n YAML:

```yaml
# configs/mi_config.yaml
data_sources:
  clinical_data: "data/IPSSMol/df_clinical.tsv"
  mutation_vaf_data: "data/IPSSMol/maf.tsv"
  gene_embeddings: "data/scGPT/gene_embeddings.csv"

variable_processing:
  gene_selection:
    - "TP53"
    - "ASXL1"
    - "RUNX1"
  
  continuous_variables:
    - "AGE"
    - "HB"
    - "PLT"
  
  categorical_variables:
    - "SEX"
  
  binary_variables:
    - "AML_TRANSF"
  
  survival_variables:
    time_variable: "LFS_YEARS"
    status_variable: "LFS_STATUS"

cross_validation:
  fold_column: "fold"

data_generation:
  output_formats: ["table", "graph"]
  table_format:
    output_filename: "mi_experimento_table"
  graph_format:
    output_filename: "mi_experimento_graph"

output:
  file_prefix: "mi_experimento"
```

### 2. EjecuciÃ³n BÃ¡sica

```bash
# EjecuciÃ³n local
python prepare_data_unified.py \
    --config configs/mi_config.yaml \
    --output results/mi_experimento

# EjecuciÃ³n con Docker
docker run --rm \
    -v /ruta/completa/MDS_subtypes:/workspace \
    mds_subtypes_python:1.6 \
    python /workspace/scripts/3.GeneticScores/prepare_data_unified.py \
    --config /workspace/scripts/3.GeneticScores/configs/mi_config.yaml \
    --output /workspace/results/mi_experimento
```

### 3. ValidaciÃ³n de Resultados

```bash
# ValidaciÃ³n de calidad
python tests/validate_step3c.py \
    --data-dir results/mi_experimento

# ValidaciÃ³n de compatibilidad con modelos
python tests/validate_step3d.py \
    --data-dir results/mi_experimento

# ValidaciÃ³n completa automatizada
python tests/run_pipeline_and_validate.py \
    --config configs/mi_config.yaml \
    --output results/mi_experimento_validado
```

## ğŸ’¡ Ejemplos PrÃ¡cticos

### Ejemplo 1: AnÃ¡lisis BÃ¡sico con Genes EspecÃ­ficos

```python
# examples/basic_analysis.py
import yaml
from pathlib import Path
import subprocess

# ConfiguraciÃ³n bÃ¡sica
config = {
    'data_sources': {
        'clinical_data': 'data/IPSSMol/df_clinical.tsv',
        'mutation_vaf_data': 'data/IPSSMol/maf.tsv',
        'gene_embeddings': 'data/scGPT/gene_embeddings.csv'
    },
    'variable_processing': {
        'gene_selection': ['TP53', 'ASXL1', 'RUNX1', 'SRSF2', 'SF3B1'],
        'continuous_variables': ['AGE', 'HB', 'PLT', 'ANC'],
        'categorical_variables': ['SEX'],
        'binary_variables': ['AML_TRANSF'],
        'survival_variables': {
            'time_variable': 'LFS_YEARS',
            'status_variable': 'LFS_STATUS'
        }
    },
    'cross_validation': {'fold_column': 'fold'},
    'data_generation': {
        'output_formats': ['table', 'graph'],
        'table_format': {'output_filename': 'basic_table'},
        'graph_format': {'output_filename': 'basic_graph'}
    },
    'output': {'file_prefix': 'basic_analysis'}
}

# Guardar configuraciÃ³n
config_file = Path('configs/basic_analysis.yaml')
with open(config_file, 'w') as f:
    yaml.dump(config, f)

# Ejecutar pipeline
result = subprocess.run([
    'python', 'prepare_data_unified.py',
    '--config', str(config_file),
    '--output', 'results/basic_analysis',
    '--verbose'
], capture_output=True, text=True)

print("STDOUT:", result.stdout)
if result.stderr:
    print("STDERR:", result.stderr)
```

### Ejemplo 2: AnÃ¡lisis Completo con ValidaciÃ³n

```python
# examples/complete_analysis.py
import subprocess
from pathlib import Path

def run_complete_analysis():
    """Ejecuta anÃ¡lisis completo con validaciÃ³n."""
    
    # 1. Ejecutar pipeline
    print("ğŸš€ Ejecutando pipeline de datos...")
    pipeline_result = subprocess.run([
        'python', 'prepare_data_unified.py',
        '--config', 'configs/real_data_config.yaml',
        '--output', 'results/complete_analysis'
    ], capture_output=True, text=True)
    
    if pipeline_result.returncode != 0:
        print("âŒ Error en pipeline:", pipeline_result.stderr)
        return False
    
    # 2. Validar calidad
    print("ğŸ” Validando calidad de datos...")
    quality_result = subprocess.run([
        'python', 'tests/validate_step3c.py',
        '--data-dir', 'results/complete_analysis'
    ], capture_output=True, text=True)
    
    # 3. Validar compatibilidad
    print("ğŸ§ª Validando compatibilidad con modelos...")
    compat_result = subprocess.run([
        'python', 'tests/validate_step3d.py',
        '--data-dir', 'results/complete_analysis'
    ], capture_output=True, text=True)
    
    # 4. Resumen
    print("\n" + "="*50)
    print("RESUMEN DEL ANÃLISIS COMPLETO")
    print("="*50)
    print(f"Pipeline: {'âœ… OK' if pipeline_result.returncode == 0 else 'âŒ ERROR'}")
    print(f"Calidad: {'âœ… OK' if quality_result.returncode == 0 else 'âŒ ERROR'}")
    print(f"Compatibilidad: {'âœ… OK' if compat_result.returncode == 0 else 'âŒ ERROR'}")
    
    return all(r.returncode == 0 for r in [pipeline_result, quality_result, compat_result])

if __name__ == "__main__":
    success = run_complete_analysis()
    exit(0 if success else 1)
```

### Ejemplo 3: AnÃ¡lisis con Docker

```bash
#!/bin/bash
# examples/docker_analysis.sh

# Variables
IMAGE="mds_subtypes_python:1.6"
WORKSPACE="/workspace"
CONFIG="configs/real_data_config.yaml"
OUTPUT="results/docker_analysis"

echo "ğŸ³ Ejecutando anÃ¡lisis completo con Docker..."

# 1. Pipeline principal
echo "ğŸ“Š Ejecutando pipeline..."
docker run --rm \
    -v "$(pwd)/../..:/workspace" \
    $IMAGE \
    python $WORKSPACE/scripts/3.GeneticScores/prepare_data_unified.py \
    --config $WORKSPACE/scripts/3.GeneticScores/$CONFIG \
    --output $WORKSPACE/$OUTPUT \
    --verbose

# 2. ValidaciÃ³n de calidad
echo "ğŸ” Validando calidad..."
docker run --rm \
    -v "$(pwd)/../..:/workspace" \
    $IMAGE \
    python $WORKSPACE/scripts/3.GeneticScores/tests/validate_step3c.py \
    --data-dir $WORKSPACE/$OUTPUT

# 3. ValidaciÃ³n de compatibilidad
echo "ğŸ§ª Validando compatibilidad..."
docker run --rm \
    -v "$(pwd)/../..:/workspace" \
    $IMAGE \
    python $WORKSPACE/scripts/3.GeneticScores/tests/validate_step3d.py \
    --data-dir $WORKSPACE/$OUTPUT

echo "âœ… AnÃ¡lisis completado. Revisa $OUTPUT para los resultados."
```

## ğŸ”¬ ValidaciÃ³n y Pruebas

### Tipos de ValidaciÃ³n

1. **ValidaciÃ³n de IntegraciÃ³n** (`validate_step2b.py`)
   - Verifica que todos los mÃ³dulos funcionan correctamente
   - Prueba el pipeline completo con datos de prueba

2. **ValidaciÃ³n de Calidad** (`validate_step3c.py`)
   - Verifica dimensiones, tipos de datos y estructura
   - Valida datos de supervivencia y folds
   - Detecta valores faltantes o inconsistencias

3. **ValidaciÃ³n de Compatibilidad** (`validate_step3d.py`)
   - Prueba compatibilidad con modelos NN y GNN existentes
   - Verifica forward pass de modelos
   - Valida estructuras de datos especÃ­ficas

### Comandos de ValidaciÃ³n

```bash
# ValidaciÃ³n rÃ¡pida (solo integraciÃ³n)
python tests/validate_step2b.py

# ValidaciÃ³n de calidad de datos especÃ­ficos
python tests/validate_step3c.py \
    --data-dir results/mi_experimento \
    --table-file mi_tabla.pkl \
    --graph-file mi_grafo.pt

# ValidaciÃ³n completa automatizada
python tests/run_pipeline_and_validate.py \
    --config configs/mi_config.yaml \
    --output results/validacion_completa \
    --run-quality-validation \
    --run-model-validation
```

## ğŸ”§ Troubleshooting

### Problemas Comunes

#### Error: "Archivo no encontrado"
```bash
# Verificar rutas en configuraciÃ³n
python prepare_data_unified.py --config configs/mi_config.yaml --dry-run

# Verificar estructura de archivos
ls -la data/IPSSMol/
```

#### Error: "Columnas faltantes"
```python
# Verificar columnas disponibles
import pandas as pd
df = pd.read_csv('data/IPSSMol/df_clinical.tsv', sep='\t')
print("Columnas disponibles:", df.columns.tolist())
```

#### Error de memoria con grafos grandes
```yaml
# Reducir tamaÃ±o en configuraciÃ³n
data_generation:
  graph_format:
    patient_feature_type: "clinical_only"  # Usar menos features
```

#### Incompatibilidad con modelos
```bash
# Verificar dimensiones esperadas
python tests/validate_step3d.py --data-dir results/mi_experimento --verbose

# Ajustar configuraciÃ³n segÃºn reporte de validaciÃ³n
```

### Logs y DepuraciÃ³n

```bash
# Activar logging detallado
python prepare_data_unified.py --config configs/mi_config.yaml --output results/debug --verbose

# Revisar logs
tail -f prepare_data_unified.log

# Verificar archivos generados
ls -la results/debug/
cat results/debug/quality_validation_report.txt
```

### Soporte Docker

```bash
# Verificar imagen Docker
docker images | grep mds_subtypes

# Probar container interactivo
docker run -it --rm -v $(pwd):/workspace mds_subtypes_python:1.6 bash

# Dentro del container:
cd /workspace/scripts/3.GeneticScores
python prepare_data_unified.py --help
```

## ğŸ“ Contacto y Contribuciones

Para reportar bugs, solicitar features o contribuir al proyecto:

1. Crear issue en el repositorio
2. Documentar el problema con ejemplos reproducibles
3. Incluir logs relevantes y configuraciÃ³n utilizada

---

**Nota**: Esta documentaciÃ³n cubre la versiÃ³n actual del pipeline. Para actualizaciones, consulta el changelog y la documentaciÃ³n tÃ©cnica en `/docs/`.
